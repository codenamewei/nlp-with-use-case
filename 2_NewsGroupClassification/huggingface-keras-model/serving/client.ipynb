{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import transformers as ppb #!python -m pip install transformers\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_regex(text):\n",
    "    \n",
    "    # Applies preprocessing on text\n",
    "    \n",
    "    #remove leading & end white spaces and convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove punctuation marks \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for i in text:\n",
    "        if i in punctuations: \n",
    "                text = text.replace(i, \"\")\n",
    "            \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    \n",
    "    #remove number\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"from\", \"to\", \"subject\", \"title\", \"request\", \"looking\", \"look\", \"forward\", \"cheers\", \"regards\", \"thank\", \"thanks\", \"hi\", \"all\", \"since\", \"mentioned\", \"free\", \"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"]\n",
    "MAX_TOKENIZE_LEN = 512\n",
    "def remove_stop_words(input_str):\n",
    "    \n",
    "    tokenized_words = input_str.split()\n",
    "    \n",
    "    filtered_words = [w for w in tokenized_words if not w in stop_words]\n",
    "    \n",
    "    output = \" \".join(filtered_words)\n",
    "    \n",
    "    if len(output) > MAX_TOKENIZE_LEN:\n",
    "        return output[0: MAX_TOKENIZE_LEN]\n",
    "    \n",
    "    return output  #return as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load index label\n"
     ]
    }
   ],
   "source": [
    "print('Load index label')\n",
    "label_path = \"labelclass.pickle\"\n",
    "labelhandler = open(label_path, 'rb')\n",
    "labelhandler = pickle.load(labelhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\Admin\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/distilbert-base-uncased-config.json HTTP/1.1\" 200 0\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at C:\\Users\\Admin\\.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin HTTP/1.1\" 200 0\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at C:\\Users\\Admin\\.cache\\torch\\transformers\\7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## uncomment below for  BERT instead of distilBERT\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('bert-embeddings-keras-mlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:\\\\Users\\\\chiawei\\\\konduit\\\\Github\\\\newsgroup_data\\\\20news-bydate\\\\20news-bydate-test\\\\alt.atheism\\\\53257 alt.atheism\n",
    "# D:\\\\Users\\\\chiawei\\\\konduit\\\\Github\\\\newsgroup_data\\\\20news-bydate\\\\20news-bydate-test\\\\comp.sys.ibm.pc.hardware\\\\60817 comp.sys.ibm.pc.hardware\n",
    "\n",
    "test_file_input = 'D:\\\\Users\\\\chiawei\\\\konduit\\\\Github\\\\newsgroup_data\\\\20news-bydate\\\\20news-bydate-test\\\\comp.sys.ibm.pc.hardware\\\\60817'\n",
    "\n",
    "with open(test_file_input, \"r\") as file_iterator:\n",
    "    raw_input = file_iterator.read()\n",
    "    \n",
    "processed_input = remove_stop_words(preprocess_regex(raw_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: comp.sys.ibm.pc.hardware\n",
      "Probabilities: 0.6100162863731384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_test_data = tokenizer.encode(processed_input, add_special_tokens=True)\n",
    "\n",
    "max_len = 512\n",
    "max_len_add = max_len\n",
    "\n",
    "if len(tokenized_test_data) > max_len:\n",
    "    max_len_add = len(tokenized_test_data)\n",
    "    \n",
    "padded_test_data = np.array([tokenized_test_data + [0]*(max_len_add-len(tokenized_test_data))])\n",
    "\n",
    "attention_test_data = np.where(padded_test_data != 0, 1, 0)\n",
    "\n",
    "input_test_ids = torch.tensor(padded_test_data)  \n",
    "attention_test_mask = torch.tensor(attention_test_data)\n",
    "\n",
    "input_test_ids = torch.tensor(input_test_ids).to(torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_test_ids, attention_mask=attention_test_mask)\n",
    "\n",
    "\n",
    "test_feature = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "test_output = classifier.predict(test_feature)\n",
    "\n",
    "local_index = int(np.argmax(test_output, 1)[0])\n",
    "\n",
    "print(\"Class: {}\".format(labelhandler[local_index]))\n",
    "print(\"Probabilities: {}\".format(np.max(test_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"GET /healthcheck HTTP/1.1\" 204 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"GET /config HTTP/1.1\" 200 923\n",
      "INFO:root:Retrieved config is\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.389534 seconds elapsed for 10 requests (0 RPS)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import logging\n",
    "import time\n",
    "from konduit.load import client_from_file\n",
    "\n",
    "logging.basicConfig(level='DEBUG')\n",
    "logging.info(\"Test\")\n",
    "\n",
    "client = client_from_file(\"config.yaml\")\n",
    "\n",
    "responses = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    response = client.predict({\"default\": test_feature})\n",
    "    responses.append(response)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"%f seconds elapsed for %d requests (%d RPS)\" % (end - start, len(responses), (10.0 / (end - start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:65322\n",
      "DEBUG:urllib3.connectionpool:http://localhost:65322 \"POST /classification/numpy HTTP/1.1\" 200 608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: comp.sys.ibm.pc.hardware\n",
      "Probabilities: 0.6100168228149414\n"
     ]
    }
   ],
   "source": [
    "response = client.predict({\"default\": test_feature})\n",
    "\n",
    "results = response[\"output\"][\"probabilities\"]\n",
    "index = int(np.argmax(response['output']['probabilities'], 1)[0])\n",
    "\n",
    "print(\"Class: {}\".format(labelhandler[index]))\n",
    "print(\"Probabilities: {}\".format(np.max(response['output']['probabilities'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
