{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 News Group Data Classification\n",
    "\n",
    "Embeddings generation using Hugging Face Bert Pretrained Model and News Group classifier trained with multi-backend Keras.  \n",
    "The model generated is then served with konduit-serving for REST inference.\n",
    "\n",
    "Konduit-Serving: https://github.com/KonduitAI/konduit-serving  \n",
    "Hugging Face NLP Library: https://github.com/huggingface/transformers  \n",
    "Data: http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers as ppb #!python -m pip install transformers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism 0\n",
      "comp.graphics 1\n",
      "comp.os.ms-windows.misc 2\n",
      "comp.sys.ibm.pc.hardware 3\n",
      "comp.sys.mac.hardware 4\n",
      "comp.windows.x 5\n",
      "misc.forsale 6\n",
      "rec.autos 7\n",
      "rec.motorcycles 8\n",
      "rec.sport.baseball 9\n",
      "rec.sport.hockey 10\n",
      "sci.crypt 11\n",
      "sci.electronics 12\n",
      "sci.med 13\n",
      "sci.space 14\n",
      "soc.religion.christian 15\n",
      "talk.politics.guns 16\n",
      "talk.politics.mideast 17\n",
      "talk.politics.misc 18\n",
      "talk.religion.misc 19\n",
      "Save index label\n"
     ]
    }
   ],
   "source": [
    "data_root_path = 'D:\\\\Users\\\\chiawei\\\\konduit\\\\Github\\\\newsgroup_data\\\\20news-bydate\\\\'\n",
    "train_folder = '20news-bydate-train'\n",
    "test_folder = '20news-bydate-test'\n",
    "file_path = 'D:\\\\Users\\\\chiawei\\\\konduit\\\\Github\\\\rpa-email-forwarder\\\\files\\\\'\n",
    "MAX_TOKENIZE_LEN = 512\n",
    "\n",
    "class_label = [f for f in os.listdir(os.path.join(data_root_path, train_folder))]\n",
    "class_index = [i for i in range(len(class_label))]\n",
    "\n",
    "total_class = len(class_index)\n",
    "\n",
    "label_index_pair = {}\n",
    "for label, index in zip(class_label, class_index):\n",
    "        label_index_pair[label] = index\n",
    "        print(label, index)\n",
    "        \n",
    "index_label_pair = {}\n",
    "for index, label in zip(class_index, class_label):\n",
    "        index_label_pair[index] = label\n",
    "\n",
    "print('Save index label')\n",
    "label_path = \"labelclass.pickle\"\n",
    "with open(label_path, 'wb') as labelhandler:\n",
    "    pickle.dump(index_label_pair, labelhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_regex(text):\n",
    "    \n",
    "    # Applies preprocessing on text\n",
    "    \n",
    "    #remove leading & end white spaces and convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove punctuation marks \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for i in text:\n",
    "        if i in punctuations: \n",
    "                text = text.replace(i, \"\")\n",
    "            \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    \n",
    "    #remove number\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"from\", \"to\", \"subject\", \"title\", \"request\", \"looking\", \"look\", \"forward\", \"cheers\", \"regards\", \"thank\", \"thanks\", \"hi\", \"all\", \"since\", \"mentioned\", \"free\", \"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"]\n",
    "\n",
    "def remove_stop_words(input_str):\n",
    "    \n",
    "    tokenized_words = input_str.split()\n",
    "    \n",
    "    filtered_words = [w for w in tokenized_words if not w in stop_words]\n",
    "    \n",
    "    output = \" \".join(filtered_words)\n",
    "    \n",
    "    if len(output) > MAX_TOKENIZE_LEN:\n",
    "        return output[0: MAX_TOKENIZE_LEN]\n",
    "    \n",
    "    return output  #return as string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs(data_path, class_dict):\n",
    "    \n",
    "    data = pd.DataFrame(columns = [\"text\", \"classindex\", \"classlabel\"])\n",
    "\n",
    "    text = []\n",
    "    class_index = []\n",
    "    class_label = []\n",
    "    \n",
    "    for label in label_index_pair.keys():\n",
    "\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        files_list = [f for f in os.listdir(class_path) ]\n",
    "\n",
    "        for f in os.listdir(class_path):\n",
    "\n",
    "            with open(os.path.join(class_path, f), \"r\") as reader:\n",
    "\n",
    "                text.append(remove_stop_words(preprocess_regex(reader.read())))\n",
    "                class_label.append(label)\n",
    "                class_index.append(class_dict[label])\n",
    "                \n",
    "    data[\"text\"] = text\n",
    "    data[\"classindex\"] = class_index\n",
    "    data[\"classlabel\"] = class_label\n",
    "                \n",
    "    return data\n",
    "\n",
    "                    \n",
    "train_data = get_dfs(os.path.join(data_root_path, train_folder), label_index_pair)\n",
    "test_data = get_dfs(os.path.join(data_root_path, test_folder), label_index_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 11314\n",
      "Number of testing data: 7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6311     mmblamarcolostateedu michael burger tv info di...\n",
       "5279     derichnetcomcom scottytissue day day day disab...\n",
       "11161    stevepcadencecom steve peterson re question sa...\n",
       "10123    masajsdccucsdedu system operator moment silenc...\n",
       "9913     serazumauucp serdar argic day night armenians ...\n",
       "4215     hagenjdwfuedu jeff hagen improvements automati...\n",
       "10867    blhuiboiseidbsuedu broward l horne month xrece...\n",
       "551      email michael abrash gmontemeiscalstateedu geo...\n",
       "2343     ziacastleedacuk zia manji help please hand sca...\n",
       "9150     jsleddssdcsasupennedu james sledd afterlife or...\n",
       "10183    bdmcsritedu brendan d mckay re deir yassin nnt...\n",
       "6944     smbresearchattcom steven bellovin re shelf che...\n",
       "5533     kingcogsciucsdedu jonathan king re zanerescue ...\n",
       "1378     kjetilkstudcsuitno kjetil kolin proteced mode ...\n",
       "10285    waldocybernetcsefauedu todd j dicker re israel...\n",
       "6845     rdippoldqualcommcom ron asbestos dippold re ta...\n",
       "6714     jfcathenamitedu john f carr re screw people cr...\n",
       "936      marching cubs abildbertcsbyuedu distribution w...\n",
       "6346     organization university notre dame office univ...\n",
       "7784     dyerspdcccom steve dyer re msg sensitivity sup...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle data\n",
    "train_data = train_data.reindex(np.random.permutation(train_data.index))\n",
    "test_data = test_data.reindex(np.random.permutation(test_data.index))\n",
    "\n",
    "print(\"Number of training data: {}\".format(train_data.shape[0]))\n",
    "print(\"Number of testing data: {}\".format(test_data.shape[0]))\n",
    "\n",
    "train_data.head(20)['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting subset of data due to memory overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[0: 6000] #6000\n",
    "test_data = test_data[0: 2000] #2000\n",
    "#train_data.to_csv(os.path.join(data_root_path, \"train_data.csv\"))\n",
    "#test_data.to_csv(os.path.join(data_root_path, \"test_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Generation:  \n",
    "Loading hugging face transformer bert pretrained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## uncomment below for  BERT instead of distilBERT\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization\n",
    "Tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = train_data['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "tokenized_test_data = test_data['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized_train_data.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "padded_train_data = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train_data.values])\n",
    "padded_test_data = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test_data.values])\n",
    "\n",
    "#print(\"Shape of input data: {}\".format(padded_train_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking of padded data  \n",
    "Masking tells the NLP model to ignore (mask) the padding added when it's processing its input.  \n",
    "That's what attention_mask is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 317)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention_mask = np.where(padded_train_data != 0, 1, 0)\n",
    "test_attention_mask = np.where(padded_test_data != 0, 1, 0)\n",
    "train_attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings through Hugging Face Bert using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "\n",
    "from tensorflow.keras import backend\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 512\n",
    "epoch_count = 20\n",
    "labels = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Miniconda3\\envs\\kerasenv\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "pytrain_input_ids = torch.tensor(padded_train_data)  \n",
    "pytrain_attention_mask = torch.tensor(train_attention_mask)\n",
    "\n",
    "pytrain_input_ids = torch.tensor(pytrain_input_ids).to(torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(pytrain_input_ids, attention_mask=pytrain_attention_mask)\n",
    "    \n",
    "train_features = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "train_labels = np.expand_dims(train_data[\"classindex\"], axis = 1)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Miniconda3\\envs\\kerasenv\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytest_input_ids = torch.tensor(padded_test_data)  \n",
    "pytest_attention_mask = torch.tensor(test_attention_mask)\n",
    "\n",
    "pytest_input_ids = torch.tensor(pytest_input_ids).to(torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(pytest_input_ids, attention_mask=pytest_attention_mask)\n",
    "    \n",
    "test_features = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "test_labels = np.expand_dims(test_data[\"classindex\"], axis = 1)\n",
    "\n",
    "test_labels = keras.utils.to_categorical(test_labels, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings with tf-backend Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 2.7616 - accuracy: 0.2205 - val_loss: 2.3991 - val_accuracy: 0.4110\n",
      "Epoch 2/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 2.1125 - accuracy: 0.4077 - val_loss: 1.8361 - val_accuracy: 0.4655\n",
      "Epoch 3/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.6549 - accuracy: 0.4907 - val_loss: 1.5385 - val_accuracy: 0.5280\n",
      "Epoch 4/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.3964 - accuracy: 0.5492 - val_loss: 1.3834 - val_accuracy: 0.5425\n",
      "Epoch 5/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.2472 - accuracy: 0.5930 - val_loss: 1.2895 - val_accuracy: 0.5775\n",
      "Epoch 6/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.1527 - accuracy: 0.6175 - val_loss: 1.2449 - val_accuracy: 0.5910\n",
      "Epoch 7/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.0914 - accuracy: 0.6367 - val_loss: 1.2183 - val_accuracy: 0.5900\n",
      "Epoch 8/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 1.0351 - accuracy: 0.6587 - val_loss: 1.1897 - val_accuracy: 0.6060\n",
      "Epoch 9/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.9852 - accuracy: 0.6747 - val_loss: 1.1589 - val_accuracy: 0.6150\n",
      "Epoch 10/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.9496 - accuracy: 0.6850 - val_loss: 1.1622 - val_accuracy: 0.6140\n",
      "Epoch 11/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.9165 - accuracy: 0.6948 - val_loss: 1.1339 - val_accuracy: 0.6240\n",
      "Epoch 12/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.8921 - accuracy: 0.7012 - val_loss: 1.1254 - val_accuracy: 0.6240\n",
      "Epoch 13/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.8655 - accuracy: 0.7130 - val_loss: 1.1100 - val_accuracy: 0.6275\n",
      "Epoch 14/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.8288 - accuracy: 0.7248 - val_loss: 1.0931 - val_accuracy: 0.6400\n",
      "Epoch 15/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.8022 - accuracy: 0.7315 - val_loss: 1.0910 - val_accuracy: 0.6385\n",
      "Epoch 16/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7883 - accuracy: 0.7353 - val_loss: 1.1105 - val_accuracy: 0.6345\n",
      "Epoch 17/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7703 - accuracy: 0.7508 - val_loss: 1.1007 - val_accuracy: 0.6470\n",
      "Epoch 18/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7533 - accuracy: 0.7473 - val_loss: 1.0742 - val_accuracy: 0.6455\n",
      "Epoch 19/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7389 - accuracy: 0.7538 - val_loss: 1.0822 - val_accuracy: 0.6545\n",
      "Epoch 20/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7095 - accuracy: 0.7622 - val_loss: 1.0847 - val_accuracy: 0.6450\n",
      "Epoch 21/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.7025 - accuracy: 0.7655 - val_loss: 1.0911 - val_accuracy: 0.6485\n",
      "Epoch 22/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6926 - accuracy: 0.7708 - val_loss: 1.0699 - val_accuracy: 0.6465\n",
      "Epoch 23/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6730 - accuracy: 0.7753 - val_loss: 1.0713 - val_accuracy: 0.6535\n",
      "Epoch 24/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6408 - accuracy: 0.7903 - val_loss: 1.0648 - val_accuracy: 0.6600\n",
      "Epoch 25/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6353 - accuracy: 0.7913 - val_loss: 1.0638 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "6000/6000 [==============================] - 0s 11us/step - loss: 0.6270 - accuracy: 0.7927 - val_loss: 1.0724 - val_accuracy: 0.6540\n",
      "Epoch 27/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6060 - accuracy: 0.8032 - val_loss: 1.0872 - val_accuracy: 0.6510\n",
      "Epoch 28/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.6020 - accuracy: 0.8045 - val_loss: 1.0769 - val_accuracy: 0.6640\n",
      "Epoch 29/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5882 - accuracy: 0.8088 - val_loss: 1.0625 - val_accuracy: 0.6590\n",
      "Epoch 30/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5644 - accuracy: 0.8118 - val_loss: 1.0915 - val_accuracy: 0.6540\n",
      "Epoch 31/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5621 - accuracy: 0.8133 - val_loss: 1.0939 - val_accuracy: 0.6480\n",
      "Epoch 32/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5511 - accuracy: 0.8188 - val_loss: 1.0811 - val_accuracy: 0.6565\n",
      "Epoch 33/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5486 - accuracy: 0.8175 - val_loss: 1.0971 - val_accuracy: 0.6565\n",
      "Epoch 34/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5327 - accuracy: 0.8273 - val_loss: 1.0679 - val_accuracy: 0.6655\n",
      "Epoch 35/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.5081 - accuracy: 0.8318 - val_loss: 1.0966 - val_accuracy: 0.6590\n",
      "Epoch 36/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4982 - accuracy: 0.8362 - val_loss: 1.0800 - val_accuracy: 0.6605\n",
      "Epoch 37/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4807 - accuracy: 0.8430 - val_loss: 1.0929 - val_accuracy: 0.6710\n",
      "Epoch 38/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4783 - accuracy: 0.8458 - val_loss: 1.0868 - val_accuracy: 0.6590\n",
      "Epoch 39/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4696 - accuracy: 0.8487 - val_loss: 1.0945 - val_accuracy: 0.6655\n",
      "Epoch 40/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4650 - accuracy: 0.8492 - val_loss: 1.1155 - val_accuracy: 0.6590\n",
      "Epoch 41/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4491 - accuracy: 0.8520 - val_loss: 1.1013 - val_accuracy: 0.6600\n",
      "Epoch 42/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4423 - accuracy: 0.8615 - val_loss: 1.1108 - val_accuracy: 0.6640\n",
      "Epoch 43/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4201 - accuracy: 0.8630 - val_loss: 1.1246 - val_accuracy: 0.6625\n",
      "Epoch 44/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4163 - accuracy: 0.8670 - val_loss: 1.1430 - val_accuracy: 0.6515\n",
      "Epoch 45/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.4046 - accuracy: 0.8740 - val_loss: 1.1414 - val_accuracy: 0.6585\n",
      "Epoch 46/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.3989 - accuracy: 0.8683 - val_loss: 1.1490 - val_accuracy: 0.6620\n",
      "Epoch 47/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.3903 - accuracy: 0.8772 - val_loss: 1.1308 - val_accuracy: 0.6585\n",
      "Epoch 48/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.3808 - accuracy: 0.8770 - val_loss: 1.1684 - val_accuracy: 0.6545\n",
      "Epoch 49/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.3674 - accuracy: 0.8870 - val_loss: 1.1498 - val_accuracy: 0.6605\n",
      "Epoch 50/50\n",
      "6000/6000 [==============================] - 0s 10us/step - loss: 0.3590 - accuracy: 0.8863 - val_loss: 1.1483 - val_accuracy: 0.6560\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(250, activation='relu', input_shape=(768,)))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(250, activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(labels, activation='softmax'))\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "classifier.fit(train_features, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          validation_data = (test_features, test_labels),\n",
    "          epochs=50)#epoch_count)\n",
    "\n",
    "classifier.save('bert-embeddings-keras-mlp.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
